# Resume Job Matcher

A production-ready FastAPI backend application that intelligently matches resumes to job listings using AI and machine learning.

## ğŸš€ Quick Start

```bash
# Clone and setup
git clone <repository-url>
cd resume-job-matcher
./scripts/setup.sh

# Start development server
./scripts/start_dev.sh
```

## ğŸ“‹ Features

- **Smart Resume Analysis**: Extract skills, experience, and job titles using NLP
- **Intelligent Job Matching**: ML-powered similarity scoring with TF-IDF and cosine similarity
- **Asynchronous Processing**: Background job processing with Celery and Redis
- **Production Ready**: Docker, Kubernetes, monitoring, and comprehensive testing
- **RESTful API**: Well-documented FastAPI endpoints with automatic OpenAPI docs

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client/User   â”‚    â”‚   FastAPI App   â”‚    â”‚  Celery Worker  â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ Upload Resume   â”‚â”€â”€â”€â–¶â”‚ /api/v1/jobs/   â”‚â”€â”€â”€â–¶â”‚ Process Resume  â”‚
â”‚ Check Status    â”‚    â”‚ /api/v1/tasks/  â”‚    â”‚ Extract Skills  â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚ Match Jobs      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚  Redis Broker   â”‚
                                              â”‚                 â”‚
                                              â”‚ Task Queue      â”‚
                                              â”‚ Result Storage  â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
resume-job-matcher/
â”œâ”€â”€ app/                    # Main application package
â”‚   â”œâ”€â”€ api/               # API routes and endpoints
â”‚   â”œâ”€â”€ core/              # Core configuration and setup
â”‚   â”œâ”€â”€ models/            # Pydantic models
â”‚   â”œâ”€â”€ services/          # Business logic services
â”‚   â””â”€â”€ utils/             # Utility functions
â”œâ”€â”€ data/                  # Data storage
â”‚   â”œâ”€â”€ samples/          # Sample files
â”‚   â””â”€â”€ uploads/          # File uploads (if needed)
â”œâ”€â”€ deployment/            # Deployment configurations
â”‚   â”œâ”€â”€ docker/           # Docker files
â”‚   â””â”€â”€ kubernetes/       # Kubernetes manifests
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ scripts/               # Utility scripts
â”œâ”€â”€ tests/                 # Test files
â”œâ”€â”€ main.py               # Application entry point
â”œâ”€â”€ celery_worker.py      # Celery worker entry point
â””â”€â”€ requirements.txt      # Python dependencies
```

## ğŸ”§ Development

### Prerequisites

- Python 3.8+
- Redis 6.0+
- Git

### Setup

1. **Quick Setup**:
   ```bash
   ./scripts/setup.sh
   ```

2. **Manual Setup**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   pip install -r requirements.txt
   python -m spacy download en_core_web_sm
   ```

3. **Start Services**:
   ```bash
   # Start Redis
   redis-server
   
   # Start Celery worker
   celery -A app.core.celery_app.celery_app worker --loglevel=info
   
   # Start API server
   python main.py
   ```

### API Endpoints

- **API Documentation**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/api/v1/health/
- **Upload Resume**: `POST /api/v1/jobs/match`
- **Check Status**: `GET /api/v1/tasks/{task_id}/status`

## ğŸ³ Docker Deployment

```bash
# Development
docker-compose -f deployment/docker/docker-compose.yml up

# Production with monitoring
docker-compose -f deployment/docker/docker-compose.yml --profile monitoring up
```

## â˜¸ï¸ Kubernetes Deployment

```bash
kubectl apply -f deployment/kubernetes/
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run specific test files
pytest tests/test_api.py
pytest tests/test_setup.py

# Run with coverage
pytest --cov=app tests/
```

## ğŸ“Š Monitoring

- **Flower (Celery)**: http://localhost:5555 (when using monitoring profile)
- **Health Checks**: Built-in health endpoints for Kubernetes
- **Logging**: Structured logging with configurable levels

## ğŸ”’ Security

- Environment-based configuration
- Input validation and sanitization
- File type and size restrictions
- Non-root Docker containers
- Security headers and CORS configuration

## ğŸ“ˆ Performance

- Asynchronous processing with Celery
- Redis for fast caching and task queuing
- Optimized ML pipelines with scikit-learn
- Horizontal scaling support
- Resource limits and health checks

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“š Documentation

- [Setup Instructions](docs/setup_instructions.md)
- [Project Overview](docs/PROJECT_OVERVIEW.md)
- [API Documentation](http://localhost:8000/docs) (when running)

## ğŸ†˜ Support

For issues and questions:
1. Check the [documentation](docs/)
2. Run the setup verification: `python tests/test_setup.py`
3. Check the health endpoint: `curl http://localhost:8000/api/v1/health/`
4. Open an issue on GitHub